# Deployment Best Practices

As an aspiring Machine Learning Associate, understanding deployment best practices in the context of AWS is essential for certification and real-world applications.

## Versioning and Rollback Strategies

- **Versioning**: Labeling models for traceability.
- **Rollback**: Returning to a previous working model if deployment fails.

AWS provides services like **Amazon SageMaker**, **AWS CodePipeline**, and **Amazon ECR** to implement these strategies.

### Why Versioning Matters

- **Traceability** ‚Äì Track changes across versions.
- **Reproducibility** ‚Äì Re-run models with exact past conditions.
- **Collaboration** ‚Äì Safely work in teams without conflict.

### Implementing Versioning in AWS

#### Amazon SageMaker Model Registry

A centralized repository to manage:
- Model versions
- Metadata
- Approval status

**Workflow:**
1. Create model group (organize related models).
2. Build pipeline for training & deployment.
3. Register model versions after each pipeline run.
4. Monitor/manage using the registry.

**Approval Status Transitions**

| From                  | To        | Action Taken                                      |
|-----------------------|-----------|---------------------------------------------------|
| `PendingManualApproval` | `Approved` | Triggers CI/CD deployment                        |
| `PendingManualApproval` | `Rejected` | No deployment                                     |
| `Rejected`              | `Approved` | Deploys newly approved model                     |
| `Approved`              | `Rejected` | Rolls back to previously approved model          |

- Change status via **Boto3**, **SageMaker Studio**, or **SageMaker Pipelines**.

#### S3-Based Artifact Versioning

Use versioned **S3 buckets** or Git repositories to store:
- Training code
- Data
- Automation scripts

#### SageMaker Projects (Optional)

Pre-configured MLOps templates that include:
- Version control
- Pipelines
- Monitoring

### Tips for Versioning

- Use naming conventions like `modelName_v1.2.0`.
- Automate version tagging using **CodePipeline** or **Jenkins**.
- Log:
  - Hyperparameters
  - Dataset locations
  - Model performance

## Test vs. Production Environments

Strategic deployment environments are crucial for:
- Cost control
- Security
- Performance validation

### Test Environment

- Lower resource capacity
- Flexible security controls
- Optimized for **rapid iteration**
- Ideal for debugging and integration testing

**Best Practices:**
- Use smaller instance types (e.g., `ml.t2.medium`)
- Leverage **spot instances**
- Enable rapid rollback
- Monitor costs closely

### Production Environment

- High availability
- SLA guarantees
- Strong security boundaries
- Performance optimization

**Best Practices:**
- Use **auto-scaling groups**
- Choose **reserved instances** for cost savings
- Configure **CloudWatch alarms**
- Encrypt data at rest and in transit

### Implementation Considerations

- Use tight **IAM roles**
- Separate VPCs for test and production
- Enable **monitoring and logging**
- Use **capacity planning** and **load testing**
- Add:
  - Budget alerts
  - Resource tagging
  - Optimal instance selection

## Primary Services

### Amazon SageMaker

- **Endpoints configuration**: Set up secure and reliable endpoints for model inference.
- **Instance management**: Choose and scale EC2 instances for endpoints.
- **Auto-scaling policies**: Automatically increase/decrease instances based on demand.

This Python snippet shows how to set up production and test endpoint configurations using Boto3:

```python
import boto3

sagemaker_client = boto3.client("sagemaker")

# Production Configuration
sagemaker_client.create_endpoint_config(
    EndpointConfigName="prod-endpoint-config",
    ProductionVariants=[
        {
            "VariantName": "AllTraffic",
            "ModelName": "prod-model",
            "InstanceType": "ml.c5.xlarge",
            "InitialInstanceCount": 2,
            "ServerlessConfig": {
                "MaxConcurrency": 50,
                "MemorySizeInMB": 2048
            }
        }
    ]
)

# Test Configuration
sagemaker_client.create_endpoint_config(
    EndpointConfigName="test-endpoint-config",
    ProductionVariants=[
        {
            "VariantName": "TestOnly",
            "ModelName": "test-model",
            "InstanceType": "ml.c5.large",
            "InitialInstanceCount": 1
        }
    ]
)
```

### AWS Auto Scaling

- **Capacity management**: Set and maintain instance count.
- **Scaling policies**: Respond to metrics like CPU usage.
- **Target tracking**: Match actual performance with defined thresholds.

## Supporting Services

### üìà Amazon CloudWatch

- **Monitoring & Alerts**: CPU, memory, latency
- **Log management**: Centralized logs for auditing and debugging
- **Metric collection**: From AWS, applications, and log files

### üîê AWS IAM

- **Access control**: Create users, roles, and permission policies
- **Role delegation**: Grant temporary credentials to services
- **Security policies**: JSON-based permission control

## Container Options for Model Deployment

### Provided (Built-in) Containers
- Pre-built by AWS for frameworks like **TensorFlow**, **PyTorch**, etc.
- No manual setup, easy integration.
- Include security patches and version updates.

### Custom Containers
- Built using **Docker**.
- Full control over environment and dependencies.
- Ideal for custom algorithms or specific versions.
- Deployable via AWS services like **ECS**, **EKS**, or **SageMaker**.

### Key Benefits
- **Consistency**: Identical behavior in dev and production.
- **Efficiency**: Lightweight and faster than VMs.
- **Isolation**: Avoid dependency clashes.
- **Version Control**: Easy rollback and reproducibility.
- **Scalability**: Use with **ECS**, **EKS**, **SageMaker** endpoints.

## Deployment Strategy & Rollback

### Blue/Green Deployment
- Two environments: **Blue** (current), **Green** (new).
- Shift traffic to green after testing, keep blue for fallback.
- Use with **AWS CodeDeploy** and **CodePipeline**.

A blue/green deployment strategy is a best practice in model deployment. It allows you to deploy the new model version in parallel with the existing one, gradually shifting traffic to the new version while monitoring its performance. If issues are detected, you can quickly roll back to the previous version without disrupting service.

In a blue/green deployment, SageMaker provisions a new fleet with the updates (the green fleet). Then, SageMaker shifts traffic from the old fleet (the blue fleet) to the green fleet. Once the green fleet operates smoothly for a set evaluation period (called the baking period), SageMaker terminates the blue fleet. You can specify Amazon CloudWatch alarms that SageMaker uses to monitor the green fleet. If an issue with the updated code trips any of the alarms, SageMaker initiates an auto-rollback to the blue fleet in order to maintain availability thereby minimizing risk.

### Canary Deployment
- Gradually shift traffic to the new model version.
- Monitor performance before full rollout.
- Adjust via `InitialVariantWeight` in **SageMaker endpoint** config.

### Product variants (SageMaker Endpoints)

Efficiently managing and updating machine learning models in production requires a strategy that enables safe evaluation of new model versions without interrupting service or risking degraded performance. Amazon SageMaker endpoint variants allow gradual traffic shifting to new models, facilitating real-time performance comparison under actual workload conditions.

A feature in Amazon SageMaker that allows multiple models to be hosted behind a single endpoint, with configurable traffic routing weights to distribute inference requests among the models.

Using production variants in Amazon SageMaker is the most effective way to implement online validation with minimal operational overhead. By adding the new model as a production variant and assigning it a traffic weight of 0.2, exactly 20% of the incoming inference requests are routed to the new model, while the remaining 80% continue to use the existing model. This approach allows simultaneous serving and direct comparison of model outputs under real-world conditions.

Other options like canary traffic shifting are designed for gradual rollouts and do not maintain a fixed traffic split, while shadow variants do not route live traffic to the new model.

### Shadow variants (SageMaker Endpoints)

A SageMaker endpoint feature that sends a copy of incoming requests to a new model variant without affecting the response returned to the client, used primarily for testing without impacting live traffic. That's why it is called shadow, because you send a copy.

###  Best Practices for Rollback

- **Automate monitoring** with CloudWatch alarms to catch anomalies.
- **Maintain a stable baseline** version always ready to roll back.
- **Orchestrate with CI/CD** tools like **CodePipeline** or **Jenkins**.

## Infrastructure as Code (IaC)

- Use **AWS CDK**, **CloudFormation**, or **Terraform** to template infrastructure.
- Simplifies rollback by re-deploying a previous stable template.

## Performance, Cost, and Latency Trade-offs

| Factor       | Description                                                                       |
|--------------|-----------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------|
| Performance  | Model‚Äôs ability to handle requests and make accurate predictions                                                               |
| Cost         | Infrastructure + compute + storage cost over time                                             |
| Latency      | Time from request to prediction (low is better for real-time apps)                             |

---