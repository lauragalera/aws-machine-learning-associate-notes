# AWS Data Sources & Storage for ML

## Data Sources for Ingestion

### Databases
- Services: `RDS`, `Aurora`, `DynamoDB`, `Redshift`
- Access: JDBC/ODBC connectors
- Use **AWS DMS** for migrations or CDC

### Data Lakes (Amazon S3)
- Transfer tools: `AWS DataSync`, `S3 Transfer Acceleration`
- Massive ingestion: `Snowball`, `Snowmobile`

### Streaming Data
- **Amazon Kinesis** family:
  - `Data Streams`: Real-time ingestion
  - `Firehose`: Buffering and automatic S3/Redshift loading

### File Systems / Warehouses
- `FSx`, `EFS`: Low-latency or shared ML workloads
- `Redshift`: Scalable data warehouse for analytical workloads

## AWS Storage Services

### Amazon S3 – Core ML Data Lake

**Storage Classes**

| Class                   | Retrieval Time     | Use Case                              |
|------------------------|--------------------|----------------------------------------|
| Standard               | Milliseconds       | Frequently accessed ML datasets        |
| Intelligent-Tiering    | Milliseconds       | Unpredictable access patterns          |
| Standard-IA            | Milliseconds       | Archived models, old validation sets   |
| Glacier                | Minutes to hours   | Long-term archiving                    |
| Glacier Deep Archive   | Up to 12 hours     | Compliance or rarely retrieved data    |

**Encryption Options**
- `SSE-S3`: S3-managed keys
- `SSE-KMS`: KMS-managed (auditable)
- `SSE-C`: Customer-provided keys

**Performance Tips**
- Use prefix-based partitioning for faster lookups
- Leverage multipart uploads and `S3 Transfer Acceleration` for large files

### Amazon EFS – Shared File Access

**Modes**
- `General Purpose`: Low latency (e.g. shared notebooks)
- `Max I/O`: High throughput (e.g. parallel training)

**Optimizations**
- `EFS-IA`: Lower-cost option for less-frequent access
- Lifecycle rules to auto-transition cold data

### Amazon FSx for Lustre – High-Performance Training Storage

**Deployment Types**
- `Scratch`: Temporary high-speed storage
- `Persistent`: Durable across training jobs

**Features**
- Compression, deduplication, snapshotting
- Integrates with S3 as a fast-access cache

## Summary

Choosing the right AWS storage service is critical for balancing performance, cost, scalability, and workload requirements. Consider these factors:

- **Data Access Patterns:** Frequent access (e.g., training datasets) vs. infrequent access (archived models).
- **Throughput Requirements:** High throughput for parallel training or real-time inference workloads.
- **Scalability:** Ability to grow with expanding data volumes.
- **Cost:** Optimize for budget while meeting performance needs.

| Service                | Type    | Performance                      | Scalability | Cost Model        | Use Cases                                           |
|------------------------|---------|---------------------------------|-------------|-------------------|----------------------------------------------------|
| **Amazon S3**          | Object  | High throughput, scalable        | Massive     | Tiered, pay-as-you-go | Diverse data types, archiving, integration with many AWS services |
| **Amazon EFS**         | File    | Low latency, scalable throughput | Scalable    | Pay-as-you-go     | Shared access, model training & serving, persistent file storage |
| **Amazon FSx for Lustre** | File | Highest throughput, sub-ms latency | High throughput | Pay-as-you-go  | HPC workloads, deep learning, parallel access for large datasets |
| **Amazon FSx for ONTAP** | File   | High performance, availability, deduplication | High        | Pay-as-you-go     | Hybrid cloud ML, deduplication, data sharing with on-premises systems |