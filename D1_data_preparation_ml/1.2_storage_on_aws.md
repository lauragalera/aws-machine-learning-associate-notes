# 1.2 AWS Data Sources & Storage for ML

- [1.2.1 Data Source Types](#121-data-source-types)
  - [Database Sources](#database-sources)
  - [Object Storage Sources](#object-storage-sources)
  - [Streaming Data Sources](#streaming-data-sources)
  - [File Systems & Data Warehouses](#file-systems--data-warehouses)
- [1.2.2 AWS Storage Solutions for ML](#122-aws-storage-solutions-for-ml)
  - [Amazon S3 – Primary ML Data Lake](#amazon-s3--primary-ml-data-lake)
  - [Amazon EFS – Shared File Access](#amazon-efs--shared-file-access)
  - [Amazon FSx for Lustre – High-Performance Training](#amazon-fsx-for-lustre--high-performance-training)
  - [Amazon FSx for ONTAP – Enterprise-Grade File Storage](#amazon-fsx-for-ontap--enterprise-grade-file-storage)
- [1.2.3 Storage Selection Guidelines](#123-storage-selection-guidelines)
  - [Key Decision Factors](#key-decision-factors)
  - [Service Comparison Matrix](#service-comparison-matrix)
- [1.2.4 Extra: AWS Lake Formation](#124-extra-aws-lake-formation)
  - [Core Capabilities](#core-capabilities)
  - [Key Benefits for ML](#key-benefits-for-ml)

---

## 1.2.1 Data Source Types

### Database Sources
- **Services**: `RDS`, `Aurora`, `DynamoDB`, `Redshift`
- **Access Methods**: JDBC/ODBC connectors
- **Migration Tool**: **AWS DMS** for migrations or CDC (Change Data Capture)

### Object Storage Sources
- **Primary Service**: Amazon S3 (Data Lakes)
- **Transfer Tools**: `AWS DataSync`, `S3 Transfer Acceleration`
- **Massive Ingestion**: `Snowball`, `Snowmobile` for petabyte-scale transfers

### Streaming Data Sources
- **Amazon Kinesis Family**:
  - `Data Streams`: Real-time ingestion and processing
    - In Kinesis Data Streams, enhanced fan-out provides dedicated throughput to each consumer, ensuring faster data processing with reduced latency, which is crucial for real-time fraud detection.
  - `Firehose`: Buffering and automatic delivery to S3/Redshift
    - Configures time-based buffering for batch processing
    - Reduces API calls and maintains data consistency
    - Often used with Lambda functions for data transformation
    - Enable source record backup to S3 for data recovery

### File Systems & Data Warehouses
- **File Systems**: `FSx`, `EFS` for low-latency or shared ML workloads
- **Data Warehouse**: `Redshift` for scalable analytical workloads

---

## 1.2.2 AWS Storage Solutions for ML

### Amazon S3 – Primary ML Data Lake

#### Storage Classes for ML Workloads

| Class                   | Retrieval Time     | Use Case                              |
|------------------------|--------------------|----------------------------------------|
| **Express One Zone**   | Single-digit milliseconds | High-performance ML training, real-time inference |
| Standard               | Milliseconds       | Frequently accessed ML datasets        |
| Intelligent-Tiering    | Milliseconds       | Unpredictable access patterns          |
| Standard-IA            | Milliseconds       | Archived models, old validation sets   |
| Glacier                | Minutes to hours   | Long-term archiving                    |
| Glacier Deep Archive   | Up to 12 hours     | Compliance or rarely retrieved data    |

#### Security & Encryption
- **SSE-S3**: S3-managed keys (default)
- **SSE-KMS**: KMS-managed keys (auditable, granular control)
- **SSE-C**: Customer-provided keys (full control)

#### Performance Optimization
- **Partitioning**: Use prefix-based partitioning for faster data lookups (date)
- **Large Files**: Leverage multipart uploads and `S3 Transfer Acceleration`
- **Request Patterns**: Distribute requests across different prefixes to avoid hotspots

#### S3 Pipe Input Mode for SageMaker
Pipe input mode streams data directly from S3 into training instances:
- **Benefits**: Minimizes disk usage, immediate training start
- **Use Case**: Large datasets requiring high throughput and efficiency
- **Mechanism**: Pre-fetches data at high concurrency via named FIFO pipes
- **Limitation**: Each pipe readable by single process only

### Amazon EFS – Shared File Access

#### Performance Modes
- **General Purpose**: Low latency for shared notebooks and small-scale training
- **Max I/O**: High throughput for parallel training jobs

#### Cost Optimization
- **EFS-IA**: Infrequent Access storage class for lower costs
- **Lifecycle Policies**: Auto-transition cold data to reduce storage costs

### Amazon FSx for Lustre – High-Performance Training

- Fully managed file storage solution for high-speed, large-scale ML, HPC, and big data tasks.
- Based on Lustre (Linux + Cluster), ideal for parallel file access and distributed workloads.
- Scales up to 100 Gbps throughput, high IOPS, sub-ms latencies.

## S3 Integration
  - Links with S3, showing S3 objects as files for easy access.
  - Supports bidirectional sync and repository tasks for moving data/metadata between FSx and S3.

#### Deployment Types
- **Scratch**: Temporary high-speed storage for short-term workloads
- **Persistent**: Durable storage across multiple training jobs

#### Advanced Features
- **Data Efficiency**: Compression, deduplication, snapshotting
- **S3 Integration**: Acts as high-speed cache for S3 data
- **Performance**: Sub-millisecond latency, highest throughput

---

## 1.2.3 Storage Selection Guidelines

### Key Decision Factors
- **Data Access Patterns**: Frequent (training datasets) vs. infrequent (archived models)
- **Throughput Requirements**: High throughput for parallel training or real-time inference
- **Scalability Needs**: Ability to grow with expanding data volumes
- **Cost Optimization**: Balance budget constraints with performance requirements
- **Sharing Requirements**: Single vs. multi-user access patterns

### Service Comparison Matrix

| Service                | Type    | Performance                      | Scalability | Cost Model        | Use Cases                                           |
|------------------------|---------|---------------------------------|-------------|-------------------|----------------------------------------------------|
| **Amazon S3**          | Object  | High throughput, scalable        | Massive     | Tiered, pay-as-you-go | Diverse data types, archiving, integration with many AWS services |
| **Amazon EFS**         | File    | Low latency, scalable throughput | Scalable    | Pay-as-you-go     | Shared access, model training & serving, persistent file storage |
| **Amazon FSx for Lustre** | File | Highest throughput, sub-ms latency | High throughput | Pay-as-you-go  | HPC workloads, deep learning, parallel access for large datasets |
| **Amazon FSx for ONTAP** | File   | High performance, availability, deduplication | High        | Pay-as-you-go     | Hybrid cloud ML, deduplication, data sharing with on-premises systems |

---
## 1.2.4 Extra: AWS Lake Formation

#### Core Capabilities
- **Data Aggregation**: Combines data from multiple sources (S3, databases, on-premises)
- **Centralized Cataloging**: Creates unified data catalog for discovery and governance
- **Security Management**: Fine-grained access control and permissions
- **Multi-source Integration**: Supports PostgreSQL, S3, and other data sources

#### Key Benefits for ML
- **Simplified Data Integration**: Streamlines process of aggregating transaction logs, customer profiles, and database tables
- **Tag-based Security**: Enforces fine-grained access control using dataset tags
- **Athena Integration**: Enables secure querying without complex bucket policies
- **Scalable Governance**: Manages permissions across large, distributed datasets