# Data Cleaning and Transformation Techniques

Cleaning and transforming data are foundational steps in preparing high-quality datasets for machine learning. This chapter covers techniques for outlier detection, handling missing values, and merging or deduplicating data using both statistical and AWS-native tools.

## Outlier Detection and Removal

**Outliers** are data points that significantly deviate from the rest of the dataset. They can distort model training, reduce accuracy, and lead to biased predictions.

## Common Techniques

- **Z-Score / Standard Deviation**
  - Flag data points that fall a certain number of standard deviations from the mean.
- **Interquartile Range (IQR)**
  - Identify values outside of the 1.5√óIQR range (below Q1 - 1.5*IQR or above Q3 + 1.5*IQR).
- **Visual Methods**
  - Use **box plots** or **scatter plots** to manually detect outliers.
- **AWS Tools**
  - **SageMaker Data Wrangler**: Provides outlier detection transforms via visual interface.
  - **AWS Glue DataBrew**: Offers profiling and statistical anomaly detection.

## Imputation of Missing Data

**Missing data** occurs when some entries lack values. Imputation replaces missing values to maintain dataset completeness without discarding useful rows.

## Imputation Techniques

- **Mean / Median / Mode Imputation**
  - Replace missing values with central tendency statistics.
- **Forward Fill / Backward Fill**
  - Use the nearest previous or subsequent value to fill gaps (time series use case).
- **Predictive Imputation**
  - Train a model using existing features to predict missing values.
- **AWS Tools**
  - **SageMaker Data Wrangler**: Offers built-in imputation transforms.
  - **AWS Glue**: Supports data transformation scripts for imputation.

## Combining Datasets & Deduplication Methods

**Combining Datasets:** Merge datasets from different sources (e.g., databases, S3, APIs) using a common key such as `customer_id`.

**Deduplication:** Remove redundant records to ensure data consistency and model integrity.

### Recommended Steps

1. **Join Operations**
   - Use SQL joins, Spark joins, or Glue joins based on data size and format.
2. **Deduplication Logic**
   - Use unique identifiers and business logic to retain the most relevant records.
3. **AWS Tools**
   - **AWS Glue**
     - Use Glue jobs for merging large datasets from sources like S3, RDS, or DynamoDB.
     - Apply transformations to identify and drop duplicates.

## Summary

| Task                   | Techniques/Tools                                                             |
|------------------------|------------------------------------------------------------------------------|
| Outlier Detection      | Z-Score, IQR, Boxplots, Data Wrangler, DataBrew                             |
| Missing Data Imputation| Mean/Median/Mode, Forward/Backward Fill, Predictive Imputation              |
| Merging & Deduplication| Join Ops, Unique ID Filtering, AWS Glue                                     |

# Data Annotation and Labeling for High-Quality Datasets

## Why Data Annotation Matters
High-quality labeled datasets are essential for training accurate and reliable machine learning models. Good labels = better performance.

## Amazon SageMaker Ground Truth

**SageMaker Ground Truth** is a **fully managed labeling service** that supports:
- **Manual** annotation
- **Automated** labeling with **Active Learning**

### Features:
- Reduces labeling costs with **auto-labeling** for easy cases
- Routes complex or ambiguous data to human reviewers
- Supports workflows for **image, text, video**, and **3D point cloud** annotation

### Example
An e-commerce company wants to classify product images:
- **Automated**: Common products like phones or shirts get labeled automatically.
- **Manual**: Niche items like *banig* or *kalinga fabric* are labeled by human experts for accuracy.

## Amazon Mechanical Turk (MTurk)

**MTurk** is a **crowdsourcing platform** where you can assign micro-tasks (like labeling) to remote human workers.

### Ideal for:
- Sentiment analysis
- Image tagging
- Transcription
- Text classification

### Example
A news agency (e.g., Inquirer) wants to label thousands of comments by **sentiment** (positive/negative):
- Workers on MTurk label them quickly, building a dataset for training sentiment models.

## Best Practices for MTurk Labeling

| Best Practice                        | Description                                                       |
|-------------------------------------|-------------------------------------------------------------------|
| üìò **Clear instructions**           | Provide examples for each label class and visual guidelines       |
| ‚úÖ **Quality control**              | Use redundancy (e.g., 3 workers per item) and consensus checks     |
| üîÅ **Review mechanism**             | Validate random samples or high-disagreement data points           |

## Summary Table

| Tool                     | Use Case                                  | Key Benefit                          |
|--------------------------|--------------------------------------------|--------------------------------------|
| SageMaker Ground Truth   | Labeled dataset generation (manual + auto) | Cost-effective + scalable             |
| Amazon Mechanical Turk   | Crowdsourced human labeling                | Fast turnaround for large datasets   |

