# Data Formats and Ingestion Mechanisms

## Validated vs. Non-validated Formats

### Validated Formats
Structured data that has been cleaned and validated to ensure it conforms to expected formats.

**Includes:**
- Schema validation
- Data type enforcement
- Range/consistency checks

**Examples:**
- Cleaned `JSON`, `Parquet`, `CSV` (with validation via **Great Expectations**, **AWS Glue DataBrew**)

### Non-validated Formats
Raw, unprocessed data with potential issues in structure and integrity.

**Risks:**
- Inconsistent schema
- Incorrect types or values
- ML pipeline instability

**Examples:**
- Plain text logs
- Unstructured `JSON`
- Raw system outputs

## Common Data Formats and Their Use Cases

| Format       | Description                                                  | Use Cases                            | AWS Services                                          |
|--------------|--------------------------------------------------------------|--------------------------------------|-------------------------------------------------------|
| **CSV**      | Plain-text tabular data, comma or delimiter-separated        | Spreadsheets, exports, tabular data  | S3, Glue, Athena, Redshift, Data Wrangler             |
| **JSON**     | Semi-structured, hierarchical key-value format               | Web APIs, configs, metadata          | S3, Lambda, API Gateway, DynamoDB, Data Wrangler      |
| **Parquet**  | Compressed columnar format optimized for analytics           | Data lakes, fast querying            | S3, Glue, Athena, Redshift Spectrum, Data Wrangler    |
| **ORC**      | Efficient columnar format, ideal for Hive/Hadoop ecosystems  | Hive, big data lakes                 | S3, Glue, EMR, Hive                                   |
| **Avro**     | Row-based, schema-aware binary format                        | Event streaming, Kafka, schema evolution | S3, Kinesis, Glue, Schema Registry               |
| **RecordIO** | Binary format optimized for deep learning inputs             | Large-scale DL datasets              | MXNet, SageMaker DL Containers                        |
| **Protobuf** | Efficient cross-platform binary serialization                | Real-time comms, inter-service APIs  | S3, Kinesis, API Gateway                              |

## Choosing the Right Format

- **Data Structure:**
  - Structured: `CSV`, `Parquet`
  - Semi-structured: `JSON`
  - Evolving schemas: `Avro`
  - ML-specific: `RecordIO`, `TFRecord`

- **Compression & Performance:**
  - Formats like `Parquet`, `ORC`, and `Avro` support `Snappy`, `Gzip`, etc.
  - Enable projection & predicate pushdown for better query performance

- **Schema Evolution:**
  - Use `Avro` or `Parquet` when schema compatibility is a concern

- **Tool Compatibility:**
  - Ensure compatibility with tools like `SageMaker`, `Spark`, etc.