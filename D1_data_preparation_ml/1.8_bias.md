# 1.8 Bias Mitigation

- [1.8.1 Understanding Pre-Training Bias Metrics](#181-understanding-pre-training-bias-metrics)
  - [Difference in Proportions of Labels (DPL) vs. Conditional Demographic Disparity (CDD)](#difference-in-proportions-of-labels-dpl-conditional-demographic-disparity-cdd)
  - [Class Imbalance (CI)](#class-imbalance-ci)
  - [Bias in Different Data Types](#bias-in-different-data-types)
- [1.8.2 Using Amazon SageMaker Clarify](#182-using-amazon-sagemaker-clarify)
- [1.8.3 Identifying and Mitigating Bias in Data](#183-identifying-and-mitigating-bias-in-data)
  - [Bias Types and How to Mitigate Them](#bias-types-and-how-to-mitigate-them)
  - [Model Explainability with Clarify](#model-explainability-with-clarify)
  - [Summary](#summary)

---

## 1.8.1 Understanding Pre-Training Bias Metrics

### Why Bias Matters
Bias in machine learning data can lead to **unfair**, **discriminatory**, or **ineffective** models. Identifying bias **before training** helps improve fairness and accuracy.

**Difference in Proportions of Labels (DPL):**
DPL measures how labels (such as positive/negative outcomes) are distributed across different subgroups (e.g., region, gender, income). It highlights potential group bias by showing if one group receives a certain label more or less often than another, regardless of other factors.

**Conditional Demographic Disparity (CDD):**
CDD goes a step further by measuring the difference in positive prediction rates between demographic groups, but it does so while conditioning on relevant features (such as income, education, etc.). This means CDD can reveal subtle biases that DPL might miss, because it accounts for differences in group characteristics.

### Class Imbalance (CI)

Class imbalance occurs when **one class heavily outnumbers another**. This skews model predictions.

- The F1 score balances precision and recall, making it suitable for imbalanced datasets. 

#### Example:
In a Spanish e-commerce fraud detection dataset:
- 98% of transactions are legitimate
- 2% are fraudulent

➡️ The model might always predict "legitimate" and miss fraudulent activity.

###  Bias in Different Data Types

| Data Type     | Example of Potential Bias                                   |
|---------------|-------------------------------------------------------------|
| **Numeric**    | Income level → More approvals for higher earners            |
| **Text**       | Reviews may reflect bias against certain cultural groups    |
| **Image**      | Facial recognition favors certain features or skin tones    |

## 1.8.2 Using Amazon SageMaker Clarify

**SageMaker Clarify** provides tools for:
- **Fairness monitoring** during and after training
- Detect bias **before, during, and after** training
- Provide **bias reports**
- Offer **model explainability** insights

### What It Can Do:
- Analyze feature distributions and label proportions
- Visualize bias metrics
- Help ML teams make **fairer data and model choices**

SageMaker Clarify can be used to evaluate **feature importance**, helping you identify the most impactful features and further refine the model.

## Summary Table

| Metric                        | Purpose                              | Example Use Case                         |
|------------------------------|--------------------------------------|------------------------------------------|
| Class Imbalance (CI)         | Detect dominant vs minority classes  | Fraud detection, rare disease prediction |
| Difference in Proportions    | Detect subgroup label disparity      | Regional loan approval rates             |
| SageMaker Clarify            | Tool to analyze and monitor bias     | Identify label skew and feature bias     |

## 1.8.3 Identifying and Mitigating Bias in Data

### Bias Types and How to Mitigate Them

| Bias Type         | Description | Mitigation Approach |
|-------------------|-------------|----------------------|
| **Selection Bias** | Data not representing the entire population | Data balancing (e.g., oversampling, stratified sampling) |
| **Measurement Bias** | Inaccurate or faulty data collection | Improve instruments, standardize data collection |
| **Label Bias**     | Subjective or inconsistent labeling | Use multiple reviewers, consensus labeling, or QA processes |

###  Model Explainability with Clarify

SageMaker Clarify provides insights into:
- **Feature importance** (which inputs affect decisions)
- **Transparency & accountability** for regulated use cases (e.g., finance, healthcare)

### When to Use:
- During **data preparation**
- For **auditing**, **regulatory reviews**, or **ethical assessments**

### Summary

- Always **evaluate for bias** at each ML pipeline stage.
- Use **SageMaker Clarify** to detect and resolve biases.
- Understand **why your model behaves the way it does** using explainability features.
