# Feature Engineering, and Tools

## Feature Engineering Techniques

**Feature engineering** transforms raw data into meaningful inputs for machine learning models, improving accuracy and performance.

### Data Scaling and Standardization

- **Purpose**: Prevents large-magnitude features (e.g., price) from dominating smaller ones (e.g., number of bedrooms).
- **Techniques**:
  - **MinMaxScaler**: Scales features to a 0–1 range.
  - **StandardScaler**: Normalizes data with a mean of 0 and standard deviation of 1.

### Feature Splitting, Binning, and Log Transformation

- **Feature Binning**: Groups numeric values into ranges (e.g., purchase quantity: 1–3, 4–6, etc.)
- **Log Transformation**: Applies logarithmic scale to reduce skewness in highly variable features.

## Encoding Techniques for ML

**Encoding** transforms categorical/text data into numerical form for use in ML models.

### Encoding Techniques

| Technique        | Description | Example |
|------------------|-------------|---------|
| **One-hot Encoding** | Creates binary vectors for categories | "NCR", "Visayas", "Mindanao" → `[1, 0, 0]` |
| **Binary Encoding**  | Assigns numerical labels, then converts to binary | "Groceries" = 3 → Binary: `011` |
| **Label Encoding**   | Assigns integer values based on category order | "Silver", "Gold", "Platinum" → 0, 1, 2 |

### Tokenization for Text Data

Splits text into smaller units: **words, subwords**, or **characters**.

**Example**  
Filipino headline:  
> "Bumagsak ang presyo ng bigas sa palengke"

| Tokenization Type | Output | Use Case |
|-------------------|--------|----------|
| Word              | ["Bumagsak", "ang", "presyo", ...] | Simpler NLP tasks |
| Subword           | ["Bumag", "sak", "presyo", ...]    | Robust to unknown words |
| Character         | ["B", "u", "m", "a", ...]          | Language-agnostic models |

## Tools for Data Exploration & Feature Engineering

### **SageMaker Data Wrangler**

- No-code environment for cleaning, transforming, and visualizing data.
- Supports:
  - Outlier removal
  - Imputation
  - Feature creation
  - Balancing for classification

### AWS Glue vs AWS Glue DataBrew

| Tool       | Use Case | Interface |
|------------|----------|-----------|
| **AWS Glue** | Serverless ETL for large-scale pipelines | Script-based |
| **DataBrew** | Visual data cleaning and transformation | No-code GUI |

## Transforming Streaming Data

### Real-time Processing with AWS Lambda

- Serverless compute that reacts to events in real time
- Integrates with:
  - **Amazon Kinesis Data Streams**
  - **DynamoDB Streams**

**Example**  
A fintech company in Quezon City monitors transactions and triggers fraud alerts via Lambda when unusual patterns occur.

### Spark-based Streaming in Amazon EMR

- Leverages Apache Spark on EMR for real-time stream processing at scale
- Great for large, fast-changing datasets

**Example**  
A media company uses EMR with Spark to monitor **live viewer engagement** and update dashboards in near-real-time.

## Summary Table

| Task                      | Tool/Technique                                      |
|---------------------------|-----------------------------------------------------|
| Scale numeric data        | MinMaxScaler, StandardScaler                        |
| Handle skewed distributions | Binning, Log Transform                            |
| Encode categories         | One-hot, Label, Binary Encoding                    |
| Tokenize text             | Word, Subword, Character Tokenization               |
| Visual data prep          | SageMaker Data Wrangler, AWS Glue DataBrew         |
| Large ETL pipelines       | AWS Glue                                            |
| Streaming transformation  | AWS Lambda, Amazon EMR with Spark                  |
