
# 1.6 Data Cleaning, Transformation, and Annotation Techniques

- [1.6.1 Outlier Detection and Removal](#161-outlier-detection-and-removal)
- [1.6.2 Imputation of Missing Data](#162-imputation-of-missing-data)
- [1.6.3 Combining Datasets & Deduplication](#163-combining-datasets--deduplication)
- [1.6.4 Data Annotation and Labeling](#164-data-annotation-and-labeling)
  - [Amazon SageMaker Ground Truth](#amazon-sagemaker-ground-truth)
  - [Amazon Mechanical Turk (MTurk)](#amazon-mechanical-turk-mturk)
  - [Best Practices for MTurk Labeling](#best-practices-for-mturk-labeling)

---


## 1.6.1 Outlier Detection and Removal

Outliers are data points that significantly deviate from the rest of the dataset. They can distort model training, reduce accuracy, and lead to biased predictions. Common detection techniques include:

- **Z-Score / Standard Deviation**: Flag data points that fall a certain number of standard deviations from the mean.
- **Interquartile Range (IQR)**: Identify values outside of the 1.5√óIQR range.
- **Visual Methods**: Use box plots or scatter plots to manually detect outliers.
- **AWS Tools**
  - **SageMaker Data Wrangler**: Provides outlier detection transforms via visual interface.
  - **AWS Glue DataBrew**: Offers profiling and statistical anomaly detection.

#### Key Ideas
- To ensure consistent preprocessing, always reuse normalization parameters (mean, std) from training for inference. 
- Export normalization recipes from DataBrew for real-time use, and avoid recalculating parameters on new data to prevent model drift. 
- Log transformation can also reduce outlier impact and is available in DataBrew.

---
## 1.6.2 Imputation of Missing Data

Missing data occurs when some entries lack values. Imputation replaces missing values to maintain dataset completeness without discarding useful rows. Common techniques include:

- **Mean / Median / Mode Imputation**: Replace missing values with central tendency statistics.
- **Forward Fill / Backward Fill**:  Use the nearest previous or subsequent value to fill gaps (time series use case).
- **Predictive Imputation**: Train a model using existing features to predict missing values.
- **AWS Tools**
  - **SageMaker Data Wrangler**: Offers built-in imputation transforms.
  - **AWS Glue**: Supports data transformation scripts for imputation.
---
## 1.6.3 Combining Datasets & Deduplication

Combining datasets merges data from different sources (e.g., databases, S3, APIs) using a common key. Deduplication removes redundant records to ensure data consistency and model integrity.

### Recommended Steps
1. **Join Operations**: Use SQL, Spark, or Glue joins based on data size and format.
2. **Deduplication Logic**: Use unique identifiers and business logic to retain the most relevant records.
3. **AWS Tools**: Use Glue jobs for merging and deduplication at scale. 
---
## 1.6.4 Data Annotation and Labeling

High-quality labeled datasets are essential for training accurate and reliable machine learning models. Good labels = better performance.

| Tool                     | Use Case                                  | Key Benefit                          |
|--------------------------|--------------------------------------------|--------------------------------------|
| SageMaker Ground Truth   | Labeled dataset generation (manual + auto) | Cost-effective + scalable             |
| Amazon Mechanical Turk   | Crowdsourced human labeling                | Fast turnaround for large datasets   |

### Amazon SageMaker Ground Truth
- Fully managed labeling service for manual and automated annotation (active learning).
- Reduces labeling costs with auto-labeling for easy cases.
- Routes complex or ambiguous data to human reviewers.
- Supports image, text, video, and 3D point cloud annotation.
- Private workforce for sensitive data; active learning for cost savings.

### Amazon Mechanical Turk (MTurk)
- Crowdsourcing platform for micro-tasks (labeling, sentiment analysis, image tagging, transcription).
- Fast turnaround for large datasets.

#### Best Practices for MTurk Labeling
| Best Practice                        | Description                                                       |
|-------------------------------------|-------------------------------------------------------------------|
| üìò **Clear instructions**           | Provide examples for each label class and visual guidelines       |
| ‚úÖ **Quality control**              | Use redundancy (e.g., 3 workers per item) and consensus checks     |
| üîÅ **Review mechanism**             | Validate random samples or high-disagreement data points           |

