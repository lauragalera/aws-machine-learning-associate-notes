
# 4.5 ML Infrastructure Performance & Cost Optimization
- [4.5.1 Utilization: Measuring Resource Usage](#451-utilization-measuring-resource-usage)
  - [CPU Utilization](#cpu-utilization)
  - [GPU Utilization](#gpu-utilization)
  - [Memory Utilization](#memory-utilization)
  - [Storage Utilization](#storage-utilization)
  - [Tools for Resource Monitoring](#tools-for-resource-monitoring)
- [4.5.2 Throughput and Scalability](#452-throughput-and-scalability)
  - [Throughput](#throughput)
  - [Scalability](#scalability)
  - [Tools for Scalability](#tools-for-scalability)
- [4.5.3 Fault Tolerance and Availability](#453-fault-tolerance-and-availability)
  - [Availability](#availability)
  - [Fault Tolerance](#fault-tolerance)
  - [Tools for Fault Tolerance & Availability](#tools-for-fault-tolerance--availability)
- [4.5.4 Tools for Infrastructure Monitoring](#454-tools-for-infrastructure-monitoring)
  - [CloudWatch Dashboards](#cloudwatch-dashboards-building-custom-dashboards-to-track-performance-metrics)
  - [EventBridge](#eventbridge-automating-responses-to-infrastructure-changes-and-performance-anomalies)
  - [SageMaker Inference Recommender](#sagemaker-inference-recommender-optimizing-instance-selection-for-inference-workloads)
  - [AWS Compute Optimizer](#aws-compute-optimizer-recommending-appropriate-instance-types-for-cost-effective-and-performant-ml-workloads)
- [4.5.5 Summary](#summary)
- [4.5.6 Best about CloudWatch](#best-about-cloudwatch)

---

## 4.5.1 Utilization: Measuring Resource Usage

Utilization metrics show how effectively infrastructure resources are used (CPU, GPU, memory, storage).

### CPU Utilization
- **Formula:** `CPU Utilization = (CPU Usage / Total CPU Capacity) × 100`
- **Best Practices:**
  - Monitor during high/low activity
  - Scale or optimize workloads if usage stays high
  - Enable multi-core processing

### GPU Utilization
- **Formula:** `GPU Utilization = (GPU Usage / Total GPU Capacity) × 100`
- **Best Practices:**
  - Distribute tasks across multiple GPUs
  - Monitor GPU memory usage

### Memory Utilization
- **Formula:** `Memory Utilization = (Memory Usage / Total Memory) × 100`
- **Best Practices:**
  - Ensure enough memory for large datasets/models
  - Use memory-efficient algorithms (e.g., mini-batch gradient descent)

### Storage Utilization
- **Formula:** `Storage Utilization = (Used Storage / Total Storage Capacity) × 100`
- **Best Practices:**
  - Monitor disk I/O
  - Clean up old models, logs, artifacts

### Tools for Resource Monitoring
- **AWS CloudWatch:** Monitor CPU, memory, disk on EC2
- **NVIDIA nvidia-smi:** Monitor GPU usage/memory
- **Prometheus + Grafana:** Real-time dashboards

---

## 4.5.2 Throughput and Scalability

### Throughput
Measures how fast the system processes data (training/inference).
- **Formula:** `Throughput = Total Data Processed / Time Taken`
- **Best Practices:**
  - Monitor data pipeline throughput (ETL jobs)
  - Scale resources to match data growth

### Scalability
System’s ability to grow and handle more load.

### Tools for Scalability
- **Amazon CloudWatch:** Throughput monitoring, auto-scaling alerts
- **EC2 Auto Scaling:** Adjust instance count
- **SageMaker Distributed Training:** Distribute workloads

---

## 4.5.3 Fault Tolerance and Availability

### Availability
Indicates system uptime over time.
- **Formula:** `Availability = (1 − Downtime / Total Time) × 100`
- **Best Practices:**
  - Use multi-AZ deployments
  - Deploy Elastic Load Balancers (ELB)

### Fault Tolerance
Ensures the system continues operating during failures.
- **Techniques:**
  - Replication: Duplicate data/models across servers/regions
  - Automatic Failover: RDS Multi-AZ, S3 cross-region replication
- **Best Practices:**
  - Schedule backups/snapshots
  - Health checks and automated replacement

### Tools for Fault Tolerance & Availability
- **Amazon CloudWatch Alarms:** Trigger actions on health issues
- **AWS ELB:** Distributes traffic for high availability
- **Amazon Route 53:** DNS-based failover routing

---

## 4.5.4 Tools for Infrastructure Monitoring

### CloudWatch Dashboards: Building Custom Dashboards to Track Performance Metrics
Amazon CloudWatch is AWS’s main monitoring tool. Create custom dashboards to track metrics from EC2, SageMaker, CloudTrail, etc.
- Custom dashboards
- Real-time monitoring
- Alerts & alarms (SNS/email)

### EventBridge: Automating Responses to Infrastructure Changes and Performance Anomalies
Amazon EventBridge is a serverless event bus for automated responses.
- Event-driven workflows (e.g., SageMaker endpoint updates)
- Integrates with Lambda, Step Functions
- Reacts to anomalies (e.g., scaling/restarting resources)

### SageMaker Inference Recommender: Optimizing Instance Selection for Inference Workloads
Helps choose the best instance type for inference by testing model performance.
- Evaluates model across instance types
- Recommends cost-effective configs (latency/throughput)
- Generates cost/latency/throughput reports

### AWS Compute Optimizer: Recommending Appropriate Instance Types for Cost-Effective and Performant ML Workloads
Analyzes resource utilization and recommends right-sizing of instances.
- Analyzes CPU, memory, storage, network usage
- Recommends better EC2 instance types
- Continuously monitors usage

---

## 4.5.5 Summary

- **CloudWatch Dashboards:** Real-time, customizable insights
- **EventBridge:** Automated responses to anomalies/updates
- **SageMaker Inference Recommender:** Efficient, high-performance inference instances
- **AWS Compute Optimizer:** Optimal instance types for cost/performance

---

## 4.5.6 Best about CloudWatch

- CloudWatch automatically collects invocation metrics for SageMaker endpoints (Invocations, InvocationErrors, Latency)
- Alarms can monitor thresholds for metrics (e.g., API calls)
- Alarms can send notifications via SNS
