# Hyperparameter Tuning

Hyperparameter tuning is the process of finding the **best combination of hyperparameters** to maximize the performance of an ML model.

## Common Hyperparameter Tuning Methods

| Method              | Description                                                                 |
|---------------------|-----------------------------------------------------------------------------|
| **Random Search**   | Fast and trial-and-error based. Picks random hyperparameter combinations.   |
| **Grid Search**     | Tries every possible combination. More accurate but slower.                 |
| **Bayesian Optimization** | Uses probability models to estimate best parameters. Accurate but computationally intensive. |
| **Hyperband**       | Combines speed and efficiency. Used in SageMaker AMT to optimize resources. |

## SageMaker Automatic Model Tuning (AMT)

SageMaker AMT automates hyperparameter tuning using **Bayesian Optimization**.

### Key Features:
- **Parallel training** → Tests multiple configurations simultaneously  
- **Cost-efficient** → Minimizes compute waste  
- **Automated** → No need for manual training loops

## Summary Table

| Method        | Speed       | Accuracy     | Best Use Case                        |
|---------------|-------------|--------------|--------------------------------------|
| Random Search | Fast        | Moderate     | Quick experimentation                |
| Grid Search   | Slow        | High         | Small parameter spaces               |
| Bayesian Opt. | Moderate    | Very High    | Complex models, performance-focused  |
| Hyperband     | Very Fast   | High         | Large search spaces, limited time    |

## What You Can Try

- Use **SageMaker AMT** to automate and speed up hyperparameter tuning.
- Combine **Hyperband** with AMT for scalable, efficient optimization.
- Explore **Bayesian Optimization** for critical applications like NLP, recommendation, and fraud detection.

# Model Hyperparameters and Performance

## What Are Hyperparameters?

Hyperparameters are configuration settings that control how your machine learning model learns. They vary depending on the model type but are crucial to performance tuning.

Hyperparameters are external configuration variables that data scientists use to manage machine learning model training. Sometimes called model hyperparameters, the hyperparameters are manually set before training a model. They're different from parameters, which are internal parameters automatically derived during the learning process and not set by data scientists.

## Important Hyperparameters Examples

| Hyperparameter       | Model Type                | Impact                                    |
|---------------------|---------------------------|-------------------------------------------|
| **Tree Depth**       | Decision Trees, Random Forests | Controls complexity; deeper trees can overfit |
| **Learning Rate**    | Most ML models            | Speed of weight updates; too high = unstable, too low = slow training |
| **Number of Layers** | Deep Learning Networks    | More layers = more powerful but computationally expensive |


Increasing the batch size allows more data to be processed in parallel, which can lead to faster training times because the model updates its weights less frequently. Reducing the number of epochs compensates for the larger batch size by ensuring the model doesn't overfit. This combination can significantly reduce training time while still allowing the model to converge effectively, provided the learning rate remains optimal.

## Balancing Bias and Variance

| Concept | Description | Effect on Model |
|---------|-------------|-----------------|
| **Bias** | Model too simple; can't capture data patterns | Underfitting; poor accuracy on both train and test data |
| **Variance** | Model too complex; fits training data too well | Overfitting; good train accuracy but poor generalization |

**Goal:** Find the optimal trade-off to avoid underfitting and overfitting.

## Key Takeaways

- Hyperparameter tuning helps optimize model accuracy and efficiency.  
- Adjust parameters carefully to balance bias and variance.  
- Use domain knowledge and validation data to guide tuning decisions.

# Methods to Reduce Model Training Time

Training a model is like preparing for a big event — the right strategies reduce wasted time and effort.

## Early Stopping

Early stopping is a proven method to prevent overfitting by halting training when the model’s performance on the validation set stops improving.

- **What it is**: Automatically halts training when model performance stops improving.
- **Why it matters**: Prevents overfitting and saves compute time.
- **Real-World Analogy**: Like taking a break during bar exam review when you're no longer absorbing anything.
- **AWS Implementation**:  
  - Use **Amazon SageMaker Automatic Model Tuning** to monitor metrics and stop training when optimal performance is reached.

## Distributed Training
- **What it is**: Splits training workload across multiple compute instances.
- **Why it matters**: Greatly accelerates training, especially for large datasets or deep learning models.
- **Real-World Analogy**: A barangay feeding program is faster with many volunteers rather than just one.
- **AWS Implementation**:
  - Use **Amazon SageMaker Distributed Training**:
    - **Data Parallelism**: Split data across workers.
    - **Model Parallelism**: Split the model across GPUs/instances.

## Reduce size

Model pruning can significantly reduce model size without sacrificing accuracy. The idea is simple: identify the redundant parameters in the model that contribute little to the training process.

Pruning and quantization are both effective methods for reducing model size. Pruning removes parts of the model that contribute little to overall performance, such as unnecessary neurons or layers, which reduces the model’s complexity. Quantization further reduces the model size by decreasing the precision of weights (e.g., from 32-bit floating-point to 8-bit integers), significantly lowering memory requirements without drastically impacting accuracy.

## Summary Table

| Method             | Purpose                         | Real-World Analogy                   | AWS Service                                |
|--------------------|----------------------------------|---------------------------------------|--------------------------------------------|
| Early Stopping     | Reduce overfitting & save time  | Take a break when review stalls      | SageMaker Automatic Model Tuning           |
| Distributed Training | Speed up training               | Many volunteers in a feeding program | SageMaker Distributed Training              |


# Factors Influencing Model Size

The size of a machine learning model affects performance, cost, and speed. A good model balances **accuracy**, **efficiency**, and **resource usage**.

## Model Architecture & Data Impact

- **Model architecture** and **input data** volume influence the final model size.
- **More parameters = larger model = slower inference**.

**AWS Tool**:  
- Use **Amazon SageMaker Neo** to compile and optimize models for faster and more scalable inference across platforms.

## Trade-offs: Complexity vs. Resources

| Model Type              | Pros                                | Cons                                 |
|-------------------------|--------------------------------------|--------------------------------------|
| Simple (e.g., linear)   | Fast and low-cost                    | Less accurate                        |
| Complex (e.g., deep learning) | High accuracy                      | Slower, needs more compute & storage |

## AWS Best Practices for Model Size Optimization

- **Pruning**: Remove unnecessary parts of the model.
- **Quantization**: Reduce the precision of model weights.
- **SageMaker Model Optimizer**: Automatically reduce model complexity while keeping performance high.

## Key Takeaways

- Balance **accuracy** and **efficiency** in your model design.
- Use AWS tools like:
  - **SageMaker Neo** for faster, optimized deployment.
  - **SageMaker Model Optimizer** for simplifying models.
- Efficient models = lower costs + better scalability.

# Improving Model Performance

Model performance refers to how well an ML model **generalizes to new, unseen data**. Improving it requires careful data handling, model configuration, and overfitting prevention.

## Key Techniques to Boost Performance

### Feature Engineering
- Transforming raw data into meaningful inputs for your model.
- Adds domain-specific insight that boosts accuracy.

### Hyperparameter Tuning
- Fine-tuning parameters that control the learning process (e.g., learning rate, number of layers).
- Can be automated in AWS using **SageMaker Automatic Model Tuning**.

## Regularization Techniques: Preventing Overfitting

Overfitting = Model does well on training data but fails on unseen data.

### Common Regularization Methods

| Technique       | Description                                                                 |
|----------------|-----------------------------------------------------------------------------|
| **L1 (Lasso)**  | Reduces some feature weights to zero, simplifying the model.                |
| **L2 (Ridge)**  | Keeps all weights but reduces large values, balancing influence.            |
| **Dropout**     | In deep learning, randomly disables neurons during training for robustness. |

## Summary

| Optimization Method    | Goal                            |
|------------------------|---------------------------------|
| Feature Engineering    | Enhance data relevance          |
| Hyperparameter Tuning  | Fine-tune model performance     |
| Regularization         | Avoid overfitting               |

## What You Can Try

- Use **SageMaker Automatic Model Tuning** to search for the best hyperparameters.
- Regularize your models using **L1**, **L2**, or **Dropout** (for deep learning).
- Apply **feature engineering** to extract behavior or context from your raw data.

# Regularization Techniques and Overfitting Prevention

## Preventing Overfitting and Underfitting with Regularization

- **Regularization** helps improve model generalization by preventing overfitting and underfitting.

### Common Regularization Techniques:
- **L1 Regularization (Lasso)**  
  Applies an absolute value penalty on coefficients, effectively dropping some features by forcing weights to zero.

  L1 regularization is beneficial for feature selection, which can improve model generalization and prevent both overfitting and underfitting.

- **L2 Regularization (Ridge)**  
  Applies a squared penalty on coefficients to keep weights small and avoid fitting noise.

- **Dropout**  
  Randomly disables neurons during training to prevent the model from relying too much on any one feature.

## Managing Catastrophic Forgetting in Neural Networks

- **Catastrophic forgetting** occurs when a neural network loses previously learned knowledge after training on new data.

### Solutions:
- **Replay Memory**  
  Combines old and new data during training to preserve past knowledge. Incorporating new data incrementally through transfer learning helps to mitigate catastrophic forgetting by allowing the model to learn new information while retaining its prior knowledge.

- **Elastic Weight Consolidation (EWC)**  
  Retains important weights from previous training to maintain prior learning.

- **Progressive Networks**  
  Adds new layers for new tasks while keeping old layers intact to preserve earlier knowledge.



