
# 2.4 AWS Services for Machine Learning: Capabilities, Pipelines, and Best Practices


## Table of Contents

- [2.4.1 AWS AI Services Overview](#241-aws-ai-services-overview)
  - [Amazon Translate](#amazon-translate)
  - [Amazon Kendra](#amazon-kendra)
  - [Amazon Polly](#amazon-polly)
  - [Amazon Transcribe](#amazon-transcribe)
  - [Amazon Textract](#amazon-textract)
  - [Amazon Comprehend](#amazon-comprehend)
  - [Amazon Lookout for Metrics](#amazon-lookout-for-metrics)
  - [Amazon Lookout for Vision](#amazon-lookout-for-vision)
  - [Amazon DevOps Guru](#amazon-devops-guru)
  - [Amazon Rekognition](#amazon-rekognition)
  - [Amazon Bedrock](#amazon-bedrock)
- [2.4.2 SageMaker No-Code/Low-Code Solutions](#242-sagemaker-no-codelow-code-solutions)
  - [SageMaker AutoPilot](#sagemaker-autopilot)
  - [SageMaker JumpStart](#sagemaker-jumpstart)
  - [SageMaker Canvas](#sagemaker-canvas)
- [2.4.3 SageMaker Built-In Algorithms](#243-sagemaker-built-in-algorithms)
  - [Overview](#overview)
  - [Common Built-In Algorithms](#common-built-in-algorithms)
- [2.4.4 Integrating and Fine-Tuning Models](#244-integrating-and-fine-tuning-models)
  - [Importing Pre-built Models](#importing-pre-built-models)
  - [Fine-tuning Pre-trained Models](#fine-tuning-pre-trained-models)
  - [Key Points](#key-points)
- [2.4.5 Model Versioning, Metadata, and Repeatability](#245-model-versioning-metadata-and-repeatability)
  - [SageMaker Model Registry](#sagemaker-model-registry)
  - [Managing Model Metadata & Model Lineage](#managing-model-metadata--model-lineage)
- [2.4.6 Model Insights and Bias Detection](#246-model-insights-and-bias-detection)
  - [SageMaker Clarify](#sagemaker-clarify)
  - [Identifying and Mitigating Model Bias](#identifying-and-mitigating-model-bias)
- [2.4.7 Convergence Issues and Debugging](#247-convergence-issues-and-debugging)
  - [Debugging Process](#debugging-process)
  - [Using SageMaker Model Debugger](#using-sagemaker-model-debugger)

---

## 2.4.1 AWS AI Services Overview



### Amazon Translate
- Managed neural machine translation (NMT) for real-time and batch text/documents
- Use batch for large jobs, real-time for apps; validate output for critical content




### Amazon Kendra
- Intelligent search with natural language understanding, multi-source indexing
- Use for enterprise/FAQ search; sync data sources and secure sensitive content





### Amazon Polly
- Text-to-speech (TTS) with neural voices, SSML, and custom lexicons
- Use for chatbots, accessibility, or voice notifications; review output for accuracy






### Amazon Transcribe
- Speech-to-text (ASR) for audio/video, real-time or batch, with speaker ID
- Use for captions, call analytics, compliance; add custom terms for accuracy


### Amazon Textract
Extracts text, forms, and tables from scanned documents and images. AnalyzeDocument API is ideal for structured data extraction. Combine with Comprehend for legal and entity analysis.

### Amazon Comprehend
NLP for sentiment analysis, entity recognition, key phrase extraction, and topic modeling. Enable logging, monitoring, and encryption for compliance.

### Amazon Lookout for Metrics
Automated anomaly detection in business and operational data. Monitors metrics, finds outliers, and reduces manual analysis.

### Amazon Lookout for Vision
Detects visual defects in images for manufacturing and quality control. No ML expertise required.

### Amazon DevOps Guru
Detects and diagnoses application issues, performance bottlenecks, and anomalies. Reduces MTTR and helps maintain ML model environments.

### Amazon Rekognition
Image and video analysis for object detection, facial recognition, and content moderation. Face Search enables real-time watchlist matching for security.



### Amazon Bedrock
- Serverless access to foundation models (chatbots, text/image generation, etc.)
- Supports vector embeddings (numerical representations for semantic search, similarity, RAG)
- Supports knowledge bases (ground LLMs with your data for retrieval-augmented generation)
- Use agents, provisioned throughput, and secure scaling
- Lower temperature/top-K for consistent LLM responses; fine-tune with domain data for relevance

**Glossary:**
- **Temperature parameter:** Controls randomness in LLM output (lower = more consistent)
- **Top-K parameter:** Limits candidate tokens for more deterministic responses
- **Caching:** Stores responses for faster, consistent answers

---

## 2.4.2 SageMaker No-Code/Low-Code Solutions

### SageMaker AutoPilot
No-code solution for automated model training, tuning, and deployment.

### SageMaker JumpStart
Pre-trained open-source models for fast development and fine-tuning.


### SageMaker Canvas
No-code ML for predictions (churn, inventory, price, classification, extraction, etc.).
**Requirements:**
- To share models or collaborate: Studio Classic user must be in the same domain as the Canvas user
- To import external models: Register the model in Model Registry before importing into Canvas
- To use datasets and save results: Canvas user must have S3 access for reading/writing data and artifacts

---

## 2.4.3 SageMaker Built-In Algorithms

### Overview
- Ready-to-use, high-performance, and scalable
- Ideal for classification, regression, clustering, anomaly detection

### Common Built-In Algorithms
1. **XGBoost**: Supervised, for classification/regression (gradient boosted trees)
2. **Linear Learner**: Supervised, for binary/multi-class classification, regression (linear/logistic regression)
3. **K-Means Clustering**: Unsupervised, for data segmentation (groups by similarity)

| Algorithm         | Type            | Use Case                          |
|------------------|------------------|-----------------------------------|
| XGBoost           | Supervised       | Fraud detection, classification   |
| Linear Learner    | Supervised       | Price prediction, classification  |
| K-Means Clustering| Unsupervised     | Customer segmentation             |

---

## 2.4.4 Integrating and Fine-Tuning Models

### Importing Pre-built Models
- Import and deploy pre-trained models (TensorFlow, PyTorch, Scikit-learn) in SageMaker
- Enables fast inference and scalable deployment

### Fine-tuning Pre-trained Models
- Further train pre-built models with your own data for better task performance
- Use JumpStart and Bedrock for foundation models and templates
- Fine-tune for local or specialized use cases
- **Best solution for low-code/no-code:** Use JumpStart, Canvas, and Data Wrangler for streamlined, scalable fine-tuning and deployment

### Key Points
- SageMaker supports seamless import and deployment of external models
- Fine-tuning with custom data improves relevance and accuracy
- JumpStart and Bedrock provide easy access to foundation models

---

## 2.4.5 Model Versioning, Metadata, and Repeatability


### SageMaker Model Registry
- **Managed service for ML model version control and governance**
- Tracks versions, approvals, metadata, and audit logs
- **Supports model approval workflows** (e.g., staging, production, archived)
- **Automates deployment rollbacks** if a new model underperforms (e.g., e-commerce platform rolls back to previous model if conversion drops)
- **Integrates with CI/CD pipelines** for automated testing and deployment
- **Best Practices:**
  - Always register models after training for traceability
  - Use tags and metadata for searchability and compliance
  - Set up approval steps to prevent untested models from reaching production




### Managing Model Metadata & Model Lineage
This is not a standalone AWS service, but a set of best practices and features (like SageMaker Model Lineage) for tracking and storing information about your ML models.

**What is model metadata?**
- Information about your model: training data versions, hyperparameters, evaluation metrics, deployment logs, approvals, etc.

**What is model lineage?**
- A SageMaker feature that automatically tracks the full history of your modelsâ€”datasets, code, parameters, and artifacts used at each step (training, tuning, deployment, etc.)
- Helps you visualize and audit the end-to-end ML workflow for traceability and compliance

**Why manage metadata and lineage?**
- Enables traceability, debugging, reproducibility, and compliance (important for regulated industries)

**How to manage metadata/lineage?**
- Use SageMaker Model Registry and SageMaker Lineage tracking, or store info in S3, DynamoDB, or your own system
- Automate metadata capture in your ML pipelines
- Regularly review metadata and lineage graphs for drift or anomalies


---

## 2.4.6 Model Insights and Bias Detection


### SageMaker Clarify
- **Analyzes training data and model performance for bias and explainability**
- Detects bias in datasets and models (pre- and post-training)
- Provides actionable insights and visualizations
- **Supports explainability reports** (feature importance, SHAP values)
- **Integrates with SageMaker pipelines** for automated bias checks
- **Best Practices:**
  - Run Clarify before and after training to catch both data and model bias
  - Use explainability reports to justify decisions to stakeholders or regulators
- **Compliance:**
  - Helps meet fairness and transparency requirements (e.g., GDPR, EEOC)



### Identifying and Mitigating Model Bias
- **Bias:** Model unfairly favors/disadvantages groups (gender, age, location, etc.)
- **Detection:**
  - Use Clarify or custom metrics to measure bias (e.g., disparate impact, equal opportunity)
- **Mitigation Strategies:**
  - Rebalance or augment training data
  - Use fairness-aware algorithms or regularization
  - Post-hoc correction (adjust predictions after training)
  - Monitor for bias drift in production
- **Example:**
  - If a model for loan approvals is less accurate for a minority group, retrain with more balanced data and monitor post-deployment
- **Best Practices:**
  - Document all bias detection and mitigation steps for compliance
  - Regularly re-evaluate models as data and regulations change


---

## 2.4.7 Convergence Issues and Debugging

### Debugging Process
1. **Issue Identification:** Check accuracy, loss curves, logs
2. **Data Analysis:** Ensure clean, balanced data
3. **Hyperparameter Optimization:** Adjust batch size, learning rate, architecture
4. **AWS Tools:** Use SageMaker Model Debugger for real-time anomaly detection

### Using SageMaker Model Debugger
- Detects training anomalies and inefficiencies
- Logs/analyzes model parameters (loss, gradients)
- Prevents issues before deployment
- Use debug rules to catch vanishing gradients, overfitting, etc.

